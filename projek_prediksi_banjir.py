# -*- coding: utf-8 -*-
"""Projek_Prediksi_Banjir.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EiNVfPZhU57sMXocyPLcMQgKUTAlrP5-

# **Projek Prediksi Banjir**

Banjir merupakan salah satu bencana alam yang sering terjadi di berbagai wilayah, termasuk Indonesia, dan dapat menyebabkan kerugian signifikan baik secara material maupun non-material. Keterlambatan dalam mendeteksi potensi banjir seringkali memperparah dampak yang ditimbulkan. Oleh karena itu, pengembangan sistem prediksi banjir yang akurat dan tepat waktu menjadi sangat penting. Dengan memanfaatkan data historis ketinggian air dari berbagai pos pemantauan, kita dapat membangun model machine learning yang mampu memberikan peringatan dini akan potensi terjadinya banjir. Proyek ini bertujuan untuk membuat model predictive analytics untuk memprediksi status banjir berdasarkan data-data tersebut.

LINK DATASET (KAGGLE) :
https://www.kaggle.com/datasets/asfilianova/dataset-banjir

# **Import Library**

Mengimpor library yang akan digunakan
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score

"""Disini semua library yang akan (dan yang mungkin akan) digunakan semuanya diimport sehingga dapat mempermudah kita dalam melakukan tahapan selanjutnya

# **Data Loading dan Cleaning**

Memuat file dataset dan menampilkannya menggunakan .head()
Disini kita akan menggunakan kolom 'Status Banjir' sebagai Target
"""

import pandas as pd

# Muat file
dataset = 'pemetaan_daerah_banjir.csv'

# Baca file CSV dari URL
data = pd.read_csv(dataset)

# Tampilkan DataFrame untuk memastikan telah dibaca dengan benar
data.head()

"""Berdasarkan tampilan .head(), kita memiliki kolom Tanggal,	Waktu,	Katulampa,	Pos Depok,	Manggarai,	Istiqlal,	Jembatan Merah,	Flusing Ancol,	Marina Ancol,	Status Banjir,	Unnamed: 10, dan	Unnamed: 11

Beberapa diantaranya mungkin akan di drop, kolom 'Status Banjir' juga merupakan kolom yang paling memungkinkan untuk kita jadikan fitur target

Menampilkan informasi umum tentang dataset
"""

print("\nInformasi dataset:")
data.info()

"""Lihat terlebih dahulu tipe data dari setiap kolom untuk memudahkan kita dilangkah berikutnya.

Cek missing values
"""

print("\nMissing values per fitur:")
print(data.isnull().sum())

"""Menghapus Kolom 11 dan 12 karena tidak relevan dan memiliki nilai null yang sangat-sangat banyak. Kolom Tanggal dan Waktu juga akan di drop karena dirasa tidak relevan"""

# Hapus kolom 'Unnamed: 10', 'Unnamed: 10', 'Tanggal', 'Waktu'
data = data.drop(columns=['Unnamed: 10', 'Unnamed: 11', 'Tanggal', 'Waktu'])

# Tampilkan DataFrame untuk memastikan kolom telah dihapus
data.head()

"""Kolom-kolom yang sebelumnya sudah dihapus membuat data yang dimiliki berbentuk 'numeric' secara seutuhnya, sehingga tidak perlu dilakukan 'labelEncoder'"""

#melakukan imputasi pada data yang kosong
cols_to_impute = ['Manggarai', 'Istiqlal', 'Jembatan Merah', 'Flusing Ancol', 'Marina Ancol']
for col in cols_to_impute:
    if data[col].isnull().any():
        median_val = data[col].median()
        data[col].fillna(median_val, inplace=True)
        print(f"Missing values di '{col}' diisi dengan median: {median_val}")

print("\nMissing values setelah imputasi:")
print(data.isnull().sum())

"""Walaupun tidak seberapa, akan kita imputasi (isi) data yang kosong dengan nilai median

# **EDA**
"""

# Distribusi fitur numerik
num_features = data.select_dtypes(include=[np.number])
plt.figure(figsize=(14, 10))
for i, column in enumerate(num_features.columns, 1):
    plt.subplot(3, 4, i)
    sns.histplot(data[column], bins=30, kde=True, color='blue')
    plt.title(f'Distribusi {column}')
plt.tight_layout()
plt.show()

"""Disini dilakukan pemeriksaan rentang nilai dari data yang ada pada setiap fitur numerik. Hasilnya seperti yang ada pada histogram diatas"""

# Heatmap korelasi untuk fitur numerik
plt.figure(figsize=(12, 10))
correlation_matrix = num_features.corr()
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)
plt.title('Heatmap Korelasi')
plt.show()

"""Disini korelasi menggunakan Heatmap digunakan supaya dapata memmberikan gambaran terhadap hubungan dari setiap fitur."""

# Pairplot untuk fitur numerik
sns.pairplot(num_features)
plt.show()

"""Pemeriksaan data 'Outlier' pada dataset juga dilakukan menggunakan Pairplot, namun untuk sekarang kita abaikan terlebih dahulu"""

# Visualisasi distribusi variabel target
plt.figure(figsize=(8, 4))
sns.countplot(x='Status Banjir', data=data, palette='viridis')
plt.title('Distribusi Variabel Target (Status Banjir)')
plt.show()

"""Perbandingan fitur target juga dilihat agar dapat dinilai apakah data seimbang atau tidak, harapannya tidak terjadi bias pada data apabila tidak seimbang

# **Data Splitting**
"""

# Buat instance MinMaxScaler
scaler = MinMaxScaler()

# Normalisasi semua kolom numerik
numeric_columns = data.select_dtypes(include=['int64', 'float64']).columns
data[numeric_columns] = scaler.fit_transform(data[numeric_columns])

# Pisahkan fitur (X) dan target (y)
X = data.drop(columns=['Status Banjir'])
y = data['Status Banjir']

# Split data menjadi set pelatihan dan set uji
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Tampilkan bentuk set pelatihan dan set uji untuk memastikan split
print(f"Training set shape: X_train={X_train.shape}, y_train={y_train.shape}")
print(f"Test set shape: X_test={X_test.shape}, y_test={y_test.shape}")

"""Data dibagi menjadi variabel fitur (X) dan variabel target (y, yaitu 'Status Banjir'). Selanjutnya, dataset dibagi menjadi data latih (80%) dan data uji (20%) menggunakan train_test_split dari sklearn.model_selection. Selain itu, data juga dibuat dalam skala yang sama melalui proses normalisasi menggunakan MinMax Scaller

# **Model Deployment**
"""

# Part 1: Model Training
# Train each classifier separately
knn = KNeighborsClassifier(n_neighbors=5)
dt = DecisionTreeClassifier(random_state=42)
rf = RandomForestClassifier(n_estimators=100, random_state=42)
svm = SVC(random_state=42)
nb = GaussianNB()

knn = KNeighborsClassifier().fit(X_train, y_train)
dt = DecisionTreeClassifier().fit(X_train, y_train)
rf = RandomForestClassifier().fit(X_train, y_train)
svm = SVC().fit(X_train, y_train)
nb = GaussianNB().fit(X_train, y_train)

print("Model training selesai.")

"""Disini digunakan beberapa model yang pernah dipelajari sebelumnya untuk mengetahui performa model mana yang paling baik

# **Model Evaluation**

## **KNN**
"""

# K-Nearest Neighbors (KNN)
y_pred_knn = knn.predict(X_test)
cm_knn = confusion_matrix(y_test, y_pred_knn)
tn, fp, fn, tp = cm_knn.ravel()
print("==== KNN Classifier ====")
print("Confusion Matrix:")
print(cm_knn)
print(f"True Positive (TP): {tp}")
print(f"False Positive (FP): {fp}")
print(f"False Negative (FN): {fn}")
print(f"True Negative (TN): {tn}")
print(f"Accuracy: {accuracy_score(y_test, y_pred_knn):.4f}")
print(f"Precision: {precision_score(y_test, y_pred_knn):.4f}")
print(f"Recall: {recall_score(y_test, y_pred_knn):.4f}")
print(f"F1-Score: {f1_score(y_test, y_pred_knn):.4f}")
print("\n" + "-"*40 + "\n")

plt.figure(figsize=(5, 4))
sns.heatmap(cm_knn, annot=True, fmt='d', cmap='Blues', cbar=False)
plt.title('KNN Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

"""Model dengan benar memprediksi 60 kejadian sebagai "Tidak Banjir". Presisi untuk kelas "Banjir" adalah 87.04%, menunjukkan bahwa dari semua yang diprediksi banjir, 87.04% di antaranya memang benar banjir. Recall sebesar 81.03% menandakan bahwa model ini berhasil mengidentifikasi 81.03% dari semua kejadian banjir yang sebenarnya. F1-Score, yang merupakan rata-rata harmonik dari presisi dan recall, adalah 83.93%.

## **Decision Tree**
"""

y_pred_dt = dt.predict(X_test)
cm_dt = confusion_matrix(y_test, y_pred_dt)
tn, fp, fn, tp = cm_dt.ravel()
print("==== Decision Tree Classifier ====")
print("Confusion Matrix:")
print(cm_dt)
print(f"True Positive (TP): {tp}")
print(f"False Positive (FP): {fp}")
print(f"False Negative (FN): {fn}")
print(f"True Negative (TN): {tn}")
print(f"Accuracy: {accuracy_score(y_test, y_pred_dt):.4f}")
print(f"Precision: {precision_score(y_test, y_pred_dt):.4f}")
print(f"Recall: {recall_score(y_test, y_pred_dt):.4f}")
print(f"F1-Score: {f1_score(y_test, y_pred_dt):.4f}")
print("\n" + "-"*40 + "\n")

plt.figure(figsize=(5, 4))
sns.heatmap(cm_dt, annot=True, fmt='d', cmap='Blues', cbar=False)
plt.title('Decision Tree Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

"""Model ini memiliki presisi yang sangat baik sebesar 92.16% untuk kelas "Banjir", artinya prediksi "Banjir" dari model ini sangat bisa diandalkan. Recall-nya sama dengan KNN yaitu 81.03%, yang menunjukkan kemampuan yang serupa dalam menemukan kasus banjir aktual. F1-Score mencapai 86.24%, mengindikasikan keseimbangan yang baik antara presisi dan recall.

## **Random Forest**
"""

# Random Forest
y_pred_rf = rf.predict(X_test)
cm_rf = confusion_matrix(y_test, y_pred_rf)
tn, fp, fn, tp = cm_rf.ravel()
print("==== Random Forest Classifier ====")
print("Confusion Matrix:")
print(cm_rf)
print(f"True Positive (TP): {tp}")
print(f"False Positive (FP): {fp}")
print(f"False Negative (FN): {fn}")
print(f"True Negative (TN): {tn}")
print(f"Accuracy: {accuracy_score(y_test, y_pred_rf):.4f}")
print(f"Precision: {precision_score(y_test, y_pred_rf):.4f}")
print(f"Recall: {recall_score(y_test, y_pred_rf):.4f}")
print(f"F1-Score: {f1_score(y_test, y_pred_rf):.4f}")
print("\n" + "-"*40 + "\n")

plt.figure(figsize=(5, 4))
sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Blues', cbar=False)
plt.title('Random Forest Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

"""Presisi model ini adalah 89.29%, yang sangat baik. Recall-nya juga tinggi, yaitu 86.21%, menunjukkan bahwa model ini baik dalam mengidentifikasi kasus "Banjir" yang sebenarnya dan juga akurat dalam prediksinya. F1-Score sebesar 87.72% adalah yang tertinggi, menandakan performa keseluruhan yang paling seimbang dan baik. Jumlah False Negatives (8) adalah yang terendah dibandingkan model lain.

## **Support Vector Machine (SVM)**
"""

# Support Vector Machine (SVM)
y_pred_svm = svm.predict(X_test)
cm_svm = confusion_matrix(y_test, y_pred_svm)
tn, fp, fn, tp = cm_svm.ravel()
print("==== SVM Classifier ====")
print("Confusion Matrix:")
print(cm_svm)
print(f"True Positive (TP): {tp}")
print(f"False Positive (FP): {fp}")
print(f"False Negative (FN): {fn}")
print(f"True Negative (TN): {tn}")
print(f"Accuracy: {accuracy_score(y_test, y_pred_svm):.4f}")
print(f"Precision: {precision_score(y_test, y_pred_svm):.4f}")
print(f"Recall: {recall_score(y_test, y_pred_svm):.4f}")
print(f"F1-Score: {f1_score(y_test, y_pred_svm):.4f}")
print("\n" + "-"*40 + "\n")

plt.figure(figsize=(5, 4))
sns.heatmap(cm_svm, annot=True, fmt='d', cmap='Blues', cbar=False)
plt.title('SVM Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

"""Presisi model ini adalah 76.81%. Yang menonjol dari SVM adalah nilai recall yang sangat tinggi yaitu 91.38%, yang berarti model ini sangat baik dalam mendeteksi hampir semua kejadian banjir yang sebenarnya, meskipun dengan konsekuensi False Positives yang lebih tinggi (16). F1-Score sebesar 83.46% menunjukkan performa yang baik, terutama didorong oleh recall yang tinggi.
5. Naive Bayes Classifier

## **Naive Bayes**
"""

# Naive Bayes
y_pred_nb = nb.predict(X_test)
cm_nb = confusion_matrix(y_test, y_pred_nb)
tn, fp, fn, tp = cm_nb.ravel()
print("==== Naive Bayes Classifier ====")
print("Confusion Matrix:")
print(cm_nb)
print(f"True Positive (TP): {tp}")
print(f"False Positive (FP): {fp}")
print(f"False Negative (FN): {fn}")
print(f"True Negative (TN): {tn}")
print(f"Accuracy: {accuracy_score(y_test, y_pred_nb):.4f}")
print(f"Precision: {precision_score(y_test, y_pred_nb):.4f}")
print(f"Recall: {recall_score(y_test, y_pred_nb):.4f}")
print(f"F1-Score: {f1_score(y_test, y_pred_nb):.4f}")
print("\n" + "-"*40 + "\n")

plt.figure(figsize=(5, 4))
sns.heatmap(cm_nb, annot=True, fmt='d', cmap='Blues', cbar=False)
plt.title('Naive Bayes Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

"""Presisi model ini adalah 58.43%. Meskipun recall-nya cukup tinggi (89.66%), yang berarti mampu mengidentifikasi sebagian besar kasus banjir aktual, tingginya angka False Positives (37) sangat menurunkan presisi dan akurasi keseluruhannya. F1-Score sebesar 70.75%.

# **Rangkuman Hasil**
"""

# Function to evaluate and return results as a dictionary
def evaluate_model(model, X_test, y_test):
    y_pred = model.predict(X_test)
    cm = confusion_matrix(y_test, y_pred)
    tn, fp, fn, tp = cm.ravel()
    results = {
        'Confusion Matrix': cm,
        'True Positive (TP)': tp,
        'False Positive (FP)': fp,
        'False Negative (FN)': fn,
        'True Negative (TN)': tn,
        'Accuracy': accuracy_score(y_test, y_pred),
        'Precision': precision_score(y_test, y_pred),
        'Recall': recall_score(y_test, y_pred),
        'F1-Score': f1_score(y_test, y_pred)
    }
    return results

# Evaluate each model and collect results
results = {
    'K-Nearest Neighbors (KNN)': evaluate_model(knn, X_test, y_test),
    'Decision Tree (DT)': evaluate_model(dt, X_test, y_test),
    'Random Forest (RF)': evaluate_model(rf, X_test, y_test),
    'Support Vector Machine (SVM)': evaluate_model(svm, X_test, y_test),
    'Naive Bayes (NB)': evaluate_model(nb, X_test, y_test)
}

# Create a DataFrame to summarize results
summary_df = pd.DataFrame(columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1-Score'])

# Populate the DataFrame with results
rows = []
for model_name, metrics in results.items():
    rows.append({
        'Model': model_name,
        'Accuracy': metrics['Accuracy'],
        'Precision': metrics['Precision'],
        'Recall': metrics['Recall'],
        'F1-Score': metrics['F1-Score']
    })

# Convert list of dictionaries to DataFrame
summary_df = pd.DataFrame(rows)

# Display the summary DataFrame
print(summary_df)